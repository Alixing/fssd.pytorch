{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.0.conv.weight \t torch.Size([64, 3, 3, 3])\n",
      "base.0.bn.weight \t torch.Size([64])\n",
      "base.0.bn.bias \t torch.Size([64])\n",
      "base.0.bn.running_mean \t torch.Size([64])\n",
      "base.0.bn.running_var \t torch.Size([64])\n",
      "base.0.bn.num_batches_tracked \t torch.Size([])\n",
      "base.2.conv.weight \t torch.Size([64, 64, 3, 3])\n",
      "base.2.bn.weight \t torch.Size([64])\n",
      "base.2.bn.bias \t torch.Size([64])\n",
      "base.2.bn.running_mean \t torch.Size([64])\n",
      "base.2.bn.running_var \t torch.Size([64])\n",
      "base.2.bn.num_batches_tracked \t torch.Size([])\n",
      "base.5.conv.weight \t torch.Size([128, 64, 3, 3])\n",
      "base.5.bn.weight \t torch.Size([128])\n",
      "base.5.bn.bias \t torch.Size([128])\n",
      "base.5.bn.running_mean \t torch.Size([128])\n",
      "base.5.bn.running_var \t torch.Size([128])\n",
      "base.5.bn.num_batches_tracked \t torch.Size([])\n",
      "base.7.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "base.7.bn.weight \t torch.Size([128])\n",
      "base.7.bn.bias \t torch.Size([128])\n",
      "base.7.bn.running_mean \t torch.Size([128])\n",
      "base.7.bn.running_var \t torch.Size([128])\n",
      "base.7.bn.num_batches_tracked \t torch.Size([])\n",
      "base.10.conv.weight \t torch.Size([256, 128, 3, 3])\n",
      "base.10.bn.weight \t torch.Size([256])\n",
      "base.10.bn.bias \t torch.Size([256])\n",
      "base.10.bn.running_mean \t torch.Size([256])\n",
      "base.10.bn.running_var \t torch.Size([256])\n",
      "base.10.bn.num_batches_tracked \t torch.Size([])\n",
      "base.12.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "base.12.bn.weight \t torch.Size([256])\n",
      "base.12.bn.bias \t torch.Size([256])\n",
      "base.12.bn.running_mean \t torch.Size([256])\n",
      "base.12.bn.running_var \t torch.Size([256])\n",
      "base.12.bn.num_batches_tracked \t torch.Size([])\n",
      "base.14.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "base.14.bn.weight \t torch.Size([256])\n",
      "base.14.bn.bias \t torch.Size([256])\n",
      "base.14.bn.running_mean \t torch.Size([256])\n",
      "base.14.bn.running_var \t torch.Size([256])\n",
      "base.14.bn.num_batches_tracked \t torch.Size([])\n",
      "base.17.conv.weight \t torch.Size([512, 256, 3, 3])\n",
      "base.17.bn.weight \t torch.Size([512])\n",
      "base.17.bn.bias \t torch.Size([512])\n",
      "base.17.bn.running_mean \t torch.Size([512])\n",
      "base.17.bn.running_var \t torch.Size([512])\n",
      "base.17.bn.num_batches_tracked \t torch.Size([])\n",
      "base.19.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "base.19.bn.weight \t torch.Size([512])\n",
      "base.19.bn.bias \t torch.Size([512])\n",
      "base.19.bn.running_mean \t torch.Size([512])\n",
      "base.19.bn.running_var \t torch.Size([512])\n",
      "base.19.bn.num_batches_tracked \t torch.Size([])\n",
      "base.21.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "base.21.bn.weight \t torch.Size([512])\n",
      "base.21.bn.bias \t torch.Size([512])\n",
      "base.21.bn.running_mean \t torch.Size([512])\n",
      "base.21.bn.running_var \t torch.Size([512])\n",
      "base.21.bn.num_batches_tracked \t torch.Size([])\n",
      "base.24.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "base.24.bn.weight \t torch.Size([512])\n",
      "base.24.bn.bias \t torch.Size([512])\n",
      "base.24.bn.running_mean \t torch.Size([512])\n",
      "base.24.bn.running_var \t torch.Size([512])\n",
      "base.24.bn.num_batches_tracked \t torch.Size([])\n",
      "base.26.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "base.26.bn.weight \t torch.Size([512])\n",
      "base.26.bn.bias \t torch.Size([512])\n",
      "base.26.bn.running_mean \t torch.Size([512])\n",
      "base.26.bn.running_var \t torch.Size([512])\n",
      "base.26.bn.num_batches_tracked \t torch.Size([])\n",
      "base.28.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "base.28.bn.weight \t torch.Size([512])\n",
      "base.28.bn.bias \t torch.Size([512])\n",
      "base.28.bn.running_mean \t torch.Size([512])\n",
      "base.28.bn.running_var \t torch.Size([512])\n",
      "base.28.bn.num_batches_tracked \t torch.Size([])\n",
      "base.31.conv.weight \t torch.Size([1024, 512, 3, 3])\n",
      "base.31.bn.weight \t torch.Size([1024])\n",
      "base.31.bn.bias \t torch.Size([1024])\n",
      "base.31.bn.running_mean \t torch.Size([1024])\n",
      "base.31.bn.running_var \t torch.Size([1024])\n",
      "base.31.bn.num_batches_tracked \t torch.Size([])\n",
      "base.33.conv.weight \t torch.Size([1024, 1024, 1, 1])\n",
      "base.33.bn.weight \t torch.Size([1024])\n",
      "base.33.bn.bias \t torch.Size([1024])\n",
      "base.33.bn.running_mean \t torch.Size([1024])\n",
      "base.33.bn.running_var \t torch.Size([1024])\n",
      "base.33.bn.num_batches_tracked \t torch.Size([])\n",
      "extras.0.conv.weight \t torch.Size([256, 1024, 1, 1])\n",
      "extras.0.bn.weight \t torch.Size([256])\n",
      "extras.0.bn.bias \t torch.Size([256])\n",
      "extras.0.bn.running_mean \t torch.Size([256])\n",
      "extras.0.bn.running_var \t torch.Size([256])\n",
      "extras.0.bn.num_batches_tracked \t torch.Size([])\n",
      "extras.1.conv.weight \t torch.Size([512, 256, 3, 3])\n",
      "extras.1.bn.weight \t torch.Size([512])\n",
      "extras.1.bn.bias \t torch.Size([512])\n",
      "extras.1.bn.running_mean \t torch.Size([512])\n",
      "extras.1.bn.running_var \t torch.Size([512])\n",
      "extras.1.bn.num_batches_tracked \t torch.Size([])\n",
      "extras.2.conv.weight \t torch.Size([128, 512, 1, 1])\n",
      "extras.2.bn.weight \t torch.Size([128])\n",
      "extras.2.bn.bias \t torch.Size([128])\n",
      "extras.2.bn.running_mean \t torch.Size([128])\n",
      "extras.2.bn.running_var \t torch.Size([128])\n",
      "extras.2.bn.num_batches_tracked \t torch.Size([])\n",
      "extras.3.conv.weight \t torch.Size([256, 128, 3, 3])\n",
      "extras.3.bn.weight \t torch.Size([256])\n",
      "extras.3.bn.bias \t torch.Size([256])\n",
      "extras.3.bn.running_mean \t torch.Size([256])\n",
      "extras.3.bn.running_var \t torch.Size([256])\n",
      "extras.3.bn.num_batches_tracked \t torch.Size([])\n",
      "ft_module.0.conv.weight \t torch.Size([256, 512, 1, 1])\n",
      "ft_module.0.bn.weight \t torch.Size([256])\n",
      "ft_module.0.bn.bias \t torch.Size([256])\n",
      "ft_module.0.bn.running_mean \t torch.Size([256])\n",
      "ft_module.0.bn.running_var \t torch.Size([256])\n",
      "ft_module.0.bn.num_batches_tracked \t torch.Size([])\n",
      "ft_module.1.conv.weight \t torch.Size([256, 1024, 1, 1])\n",
      "ft_module.1.bn.weight \t torch.Size([256])\n",
      "ft_module.1.bn.bias \t torch.Size([256])\n",
      "ft_module.1.bn.running_mean \t torch.Size([256])\n",
      "ft_module.1.bn.running_var \t torch.Size([256])\n",
      "ft_module.1.bn.num_batches_tracked \t torch.Size([])\n",
      "ft_module.2.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "ft_module.2.bn.weight \t torch.Size([256])\n",
      "ft_module.2.bn.bias \t torch.Size([256])\n",
      "ft_module.2.bn.running_mean \t torch.Size([256])\n",
      "ft_module.2.bn.running_var \t torch.Size([256])\n",
      "ft_module.2.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.0.conv.weight \t torch.Size([512, 768, 3, 3])\n",
      "pyramid_ext.0.bn.weight \t torch.Size([512])\n",
      "pyramid_ext.0.bn.bias \t torch.Size([512])\n",
      "pyramid_ext.0.bn.running_mean \t torch.Size([512])\n",
      "pyramid_ext.0.bn.running_var \t torch.Size([512])\n",
      "pyramid_ext.0.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.1.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "pyramid_ext.1.bn.weight \t torch.Size([512])\n",
      "pyramid_ext.1.bn.bias \t torch.Size([512])\n",
      "pyramid_ext.1.bn.running_mean \t torch.Size([512])\n",
      "pyramid_ext.1.bn.running_var \t torch.Size([512])\n",
      "pyramid_ext.1.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.2.conv.weight \t torch.Size([256, 512, 3, 3])\n",
      "pyramid_ext.2.bn.weight \t torch.Size([256])\n",
      "pyramid_ext.2.bn.bias \t torch.Size([256])\n",
      "pyramid_ext.2.bn.running_mean \t torch.Size([256])\n",
      "pyramid_ext.2.bn.running_var \t torch.Size([256])\n",
      "pyramid_ext.2.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.3.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "pyramid_ext.3.bn.weight \t torch.Size([256])\n",
      "pyramid_ext.3.bn.bias \t torch.Size([256])\n",
      "pyramid_ext.3.bn.running_mean \t torch.Size([256])\n",
      "pyramid_ext.3.bn.running_var \t torch.Size([256])\n",
      "pyramid_ext.3.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.4.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "pyramid_ext.4.bn.weight \t torch.Size([256])\n",
      "pyramid_ext.4.bn.bias \t torch.Size([256])\n",
      "pyramid_ext.4.bn.running_mean \t torch.Size([256])\n",
      "pyramid_ext.4.bn.running_var \t torch.Size([256])\n",
      "pyramid_ext.4.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.5.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "pyramid_ext.5.bn.weight \t torch.Size([256])\n",
      "pyramid_ext.5.bn.bias \t torch.Size([256])\n",
      "pyramid_ext.5.bn.running_mean \t torch.Size([256])\n",
      "pyramid_ext.5.bn.running_var \t torch.Size([256])\n",
      "pyramid_ext.5.bn.num_batches_tracked \t torch.Size([])\n",
      "loc.0.weight \t torch.Size([24, 512, 3, 3])\n",
      "loc.0.bias \t torch.Size([24])\n",
      "loc.1.weight \t torch.Size([24, 512, 3, 3])\n",
      "loc.1.bias \t torch.Size([24])\n",
      "loc.2.weight \t torch.Size([24, 256, 3, 3])\n",
      "loc.2.bias \t torch.Size([24])\n",
      "loc.3.weight \t torch.Size([24, 256, 3, 3])\n",
      "loc.3.bias \t torch.Size([24])\n",
      "loc.4.weight \t torch.Size([16, 256, 3, 3])\n",
      "loc.4.bias \t torch.Size([16])\n",
      "loc.5.weight \t torch.Size([16, 256, 3, 3])\n",
      "loc.5.bias \t torch.Size([16])\n",
      "conf.0.weight \t torch.Size([126, 512, 3, 3])\n",
      "conf.0.bias \t torch.Size([126])\n",
      "conf.1.weight \t torch.Size([126, 512, 3, 3])\n",
      "conf.1.bias \t torch.Size([126])\n",
      "conf.2.weight \t torch.Size([126, 256, 3, 3])\n",
      "conf.2.bias \t torch.Size([126])\n",
      "conf.3.weight \t torch.Size([126, 256, 3, 3])\n",
      "conf.3.bias \t torch.Size([126])\n",
      "conf.4.weight \t torch.Size([84, 256, 3, 3])\n",
      "conf.4.bias \t torch.Size([84])\n",
      "conf.5.weight \t torch.Size([84, 256, 3, 3])\n",
      "conf.5.bias \t torch.Size([84])\n",
      "[38, 58, 101, 121, 218, 232, 234, 282, 297, 243, 214, 199, 54, 136, 212, 70, 81, 41, 61, 135, 29, 15, 512, 512, 256, 256, 256, 256]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "w_ori = torch.load(\"FSSD_VGG_VOC_epoches_224.pth\") # add BN and l1 for FSSD \n",
    "bn = []\n",
    "percent = 0.5 # prune therefold\n",
    "for k,v in w_ori.items():\n",
    "    print (k,'\\t',v.shape)\n",
    "    if k.endswith(\"bn.weight\"):\n",
    "        bn += list(v.data.cpu().abs().numpy())\n",
    "total = len(bn)\n",
    "thre_num = int(total*percent)\n",
    "bn.sort()\n",
    "thre = bn[thre_num]\n",
    "thre = torch.tensor(float(thre)).cuda()\n",
    "mask_cfg = []\n",
    "cfg = []\n",
    "for k,v in w_ori.items():\n",
    "    if k.endswith(\"bn.weight\"):\n",
    "        mask = v.data.abs().gt(thre)\n",
    "        mask_cfg.append(mask)\n",
    "        cfg.append(torch.sum(mask).cpu().item())\n",
    "print (cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t base.0.conv.weight\n",
      "1\t base.2.conv.weight\n",
      "1\t base.5.conv.weight\n",
      "1\t base.7.conv.weight\n",
      "1\t base.10.conv.weight\n",
      "1\t base.12.conv.weight\n",
      "1\t base.14.conv.weight\n",
      "1\t base.17.conv.weight\n",
      "1\t base.19.conv.weight\n",
      "1\t base.21.conv.weight\n",
      "1\t base.24.conv.weight\n",
      "1\t base.26.conv.weight\n",
      "1\t base.28.conv.weight\n",
      "1\t base.31.conv.weight\n",
      "1\t base.33.conv.weight\n",
      "1\t extras.0.conv.weight\n",
      "1\t extras.1.conv.weight\n",
      "1\t extras.2.conv.weight\n",
      "1\t extras.3.conv.weight\n",
      "179\n",
      "1\t pyramid_ext.1.conv.weight\n",
      "1\t pyramid_ext.2.conv.weight\n",
      "1\t pyramid_ext.3.conv.weight\n",
      "1\t pyramid_ext.4.conv.weight\n",
      "1\t pyramid_ext.5.conv.weight\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "start_cfg = torch.ones(3)\n",
    "layer_id = 0\n",
    "end_cfg = mask_cfg[layer_id]\n",
    "ft_start = [\"base.21.conv.weight\",\"base.33.conv.weight\",\"extras.3.conv.weight\"]\n",
    "ft = []\n",
    "py0_ext = []\n",
    "from collections import OrderedDict\n",
    "new_weight = OrderedDict()\n",
    "for k,v in w_ori.items():\n",
    "    if 'conv' in k:\n",
    "        if not k.startswith(\"ft_module\") and k != \"pyramid_ext.0.conv.weight\":\n",
    "            idx0 = np.squeeze(np.argwhere(start_cfg.cpu().numpy()))\n",
    "            idx1 = np.squeeze(np.argwhere(end_cfg.cpu().numpy()))\n",
    "            w1 = v.data[:,idx0.tolist(),:,:]\n",
    "            new_weight[k] = w1[idx1.tolist(),:,:,:]\n",
    "            if k in ft_start:\n",
    "                ft.append(idx1.tolist())\n",
    "        elif k != \"pyramid_ext.0.conv.weight\":\n",
    "            idx0 = ft[0]\n",
    "            idx1 = np.squeeze(np.argwhere(end_cfg.cpu().numpy()))\n",
    "            w1 = v.data[:,idx0,:,:]\n",
    "            new_weight[k] = w1[idx1.tolist(),:,:,:]\n",
    "            py0_ext.append(idx1.tolist())\n",
    "            ft.pop(0)\n",
    "        else:\n",
    "            idx0 = py0_ext[0] + [256+i for i in py0_ext[1]] + [512+i for i in py0_ext[2]]\n",
    "            idx1 = np.squeeze(np.argwhere(end_cfg.cpu().numpy())) \n",
    "            w1 = v.data[:,idx0,:,:]\n",
    "            new_weight[k] = w1[idx1.tolist(),:,:,:]\n",
    "    elif 'bn' in k:\n",
    "        if 'num_batches_tracked' not in k:\n",
    "            idx1 = np.squeeze(np.argwhere(end_cfg.cpu().numpy()))\n",
    "            new_weight[k] = v.data[idx1.tolist()]\n",
    "        else:\n",
    "            new_weight[k] = v\n",
    "            start_cfg = end_cfg\n",
    "            layer_id += 1\n",
    "            if layer_id < len(mask_cfg):\n",
    "                end_cfg = mask_cfg[layer_id]\n",
    "    else:\n",
    "        new_weight[k] = v\n",
    "torch.save(new_weight,'prune.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base.0.conv.weight \t torch.Size([38, 3, 3, 3])\n",
      "base.0.bn.weight \t torch.Size([38])\n",
      "base.0.bn.bias \t torch.Size([38])\n",
      "base.0.bn.running_mean \t torch.Size([38])\n",
      "base.0.bn.running_var \t torch.Size([38])\n",
      "base.0.bn.num_batches_tracked \t torch.Size([])\n",
      "base.2.conv.weight \t torch.Size([58, 38, 3, 3])\n",
      "base.2.bn.weight \t torch.Size([58])\n",
      "base.2.bn.bias \t torch.Size([58])\n",
      "base.2.bn.running_mean \t torch.Size([58])\n",
      "base.2.bn.running_var \t torch.Size([58])\n",
      "base.2.bn.num_batches_tracked \t torch.Size([])\n",
      "base.5.conv.weight \t torch.Size([101, 58, 3, 3])\n",
      "base.5.bn.weight \t torch.Size([101])\n",
      "base.5.bn.bias \t torch.Size([101])\n",
      "base.5.bn.running_mean \t torch.Size([101])\n",
      "base.5.bn.running_var \t torch.Size([101])\n",
      "base.5.bn.num_batches_tracked \t torch.Size([])\n",
      "base.7.conv.weight \t torch.Size([121, 101, 3, 3])\n",
      "base.7.bn.weight \t torch.Size([121])\n",
      "base.7.bn.bias \t torch.Size([121])\n",
      "base.7.bn.running_mean \t torch.Size([121])\n",
      "base.7.bn.running_var \t torch.Size([121])\n",
      "base.7.bn.num_batches_tracked \t torch.Size([])\n",
      "base.10.conv.weight \t torch.Size([218, 121, 3, 3])\n",
      "base.10.bn.weight \t torch.Size([218])\n",
      "base.10.bn.bias \t torch.Size([218])\n",
      "base.10.bn.running_mean \t torch.Size([218])\n",
      "base.10.bn.running_var \t torch.Size([218])\n",
      "base.10.bn.num_batches_tracked \t torch.Size([])\n",
      "base.12.conv.weight \t torch.Size([232, 218, 3, 3])\n",
      "base.12.bn.weight \t torch.Size([232])\n",
      "base.12.bn.bias \t torch.Size([232])\n",
      "base.12.bn.running_mean \t torch.Size([232])\n",
      "base.12.bn.running_var \t torch.Size([232])\n",
      "base.12.bn.num_batches_tracked \t torch.Size([])\n",
      "base.14.conv.weight \t torch.Size([234, 232, 3, 3])\n",
      "base.14.bn.weight \t torch.Size([234])\n",
      "base.14.bn.bias \t torch.Size([234])\n",
      "base.14.bn.running_mean \t torch.Size([234])\n",
      "base.14.bn.running_var \t torch.Size([234])\n",
      "base.14.bn.num_batches_tracked \t torch.Size([])\n",
      "base.17.conv.weight \t torch.Size([282, 234, 3, 3])\n",
      "base.17.bn.weight \t torch.Size([282])\n",
      "base.17.bn.bias \t torch.Size([282])\n",
      "base.17.bn.running_mean \t torch.Size([282])\n",
      "base.17.bn.running_var \t torch.Size([282])\n",
      "base.17.bn.num_batches_tracked \t torch.Size([])\n",
      "base.19.conv.weight \t torch.Size([297, 282, 3, 3])\n",
      "base.19.bn.weight \t torch.Size([297])\n",
      "base.19.bn.bias \t torch.Size([297])\n",
      "base.19.bn.running_mean \t torch.Size([297])\n",
      "base.19.bn.running_var \t torch.Size([297])\n",
      "base.19.bn.num_batches_tracked \t torch.Size([])\n",
      "base.21.conv.weight \t torch.Size([243, 297, 3, 3])\n",
      "base.21.bn.weight \t torch.Size([243])\n",
      "base.21.bn.bias \t torch.Size([243])\n",
      "base.21.bn.running_mean \t torch.Size([243])\n",
      "base.21.bn.running_var \t torch.Size([243])\n",
      "base.21.bn.num_batches_tracked \t torch.Size([])\n",
      "base.24.conv.weight \t torch.Size([214, 243, 3, 3])\n",
      "base.24.bn.weight \t torch.Size([214])\n",
      "base.24.bn.bias \t torch.Size([214])\n",
      "base.24.bn.running_mean \t torch.Size([214])\n",
      "base.24.bn.running_var \t torch.Size([214])\n",
      "base.24.bn.num_batches_tracked \t torch.Size([])\n",
      "base.26.conv.weight \t torch.Size([199, 214, 3, 3])\n",
      "base.26.bn.weight \t torch.Size([199])\n",
      "base.26.bn.bias \t torch.Size([199])\n",
      "base.26.bn.running_mean \t torch.Size([199])\n",
      "base.26.bn.running_var \t torch.Size([199])\n",
      "base.26.bn.num_batches_tracked \t torch.Size([])\n",
      "base.28.conv.weight \t torch.Size([54, 199, 3, 3])\n",
      "base.28.bn.weight \t torch.Size([54])\n",
      "base.28.bn.bias \t torch.Size([54])\n",
      "base.28.bn.running_mean \t torch.Size([54])\n",
      "base.28.bn.running_var \t torch.Size([54])\n",
      "base.28.bn.num_batches_tracked \t torch.Size([])\n",
      "base.31.conv.weight \t torch.Size([136, 54, 3, 3])\n",
      "base.31.bn.weight \t torch.Size([136])\n",
      "base.31.bn.bias \t torch.Size([136])\n",
      "base.31.bn.running_mean \t torch.Size([136])\n",
      "base.31.bn.running_var \t torch.Size([136])\n",
      "base.31.bn.num_batches_tracked \t torch.Size([])\n",
      "base.33.conv.weight \t torch.Size([212, 136, 1, 1])\n",
      "base.33.bn.weight \t torch.Size([212])\n",
      "base.33.bn.bias \t torch.Size([212])\n",
      "base.33.bn.running_mean \t torch.Size([212])\n",
      "base.33.bn.running_var \t torch.Size([212])\n",
      "base.33.bn.num_batches_tracked \t torch.Size([])\n",
      "extras.0.conv.weight \t torch.Size([70, 212, 1, 1])\n",
      "extras.0.bn.weight \t torch.Size([70])\n",
      "extras.0.bn.bias \t torch.Size([70])\n",
      "extras.0.bn.running_mean \t torch.Size([70])\n",
      "extras.0.bn.running_var \t torch.Size([70])\n",
      "extras.0.bn.num_batches_tracked \t torch.Size([])\n",
      "extras.1.conv.weight \t torch.Size([81, 70, 3, 3])\n",
      "extras.1.bn.weight \t torch.Size([81])\n",
      "extras.1.bn.bias \t torch.Size([81])\n",
      "extras.1.bn.running_mean \t torch.Size([81])\n",
      "extras.1.bn.running_var \t torch.Size([81])\n",
      "extras.1.bn.num_batches_tracked \t torch.Size([])\n",
      "extras.2.conv.weight \t torch.Size([41, 81, 1, 1])\n",
      "extras.2.bn.weight \t torch.Size([41])\n",
      "extras.2.bn.bias \t torch.Size([41])\n",
      "extras.2.bn.running_mean \t torch.Size([41])\n",
      "extras.2.bn.running_var \t torch.Size([41])\n",
      "extras.2.bn.num_batches_tracked \t torch.Size([])\n",
      "extras.3.conv.weight \t torch.Size([61, 41, 3, 3])\n",
      "extras.3.bn.weight \t torch.Size([61])\n",
      "extras.3.bn.bias \t torch.Size([61])\n",
      "extras.3.bn.running_mean \t torch.Size([61])\n",
      "extras.3.bn.running_var \t torch.Size([61])\n",
      "extras.3.bn.num_batches_tracked \t torch.Size([])\n",
      "ft_module.0.conv.weight \t torch.Size([135, 243, 1, 1])\n",
      "ft_module.0.bn.weight \t torch.Size([135])\n",
      "ft_module.0.bn.bias \t torch.Size([135])\n",
      "ft_module.0.bn.running_mean \t torch.Size([135])\n",
      "ft_module.0.bn.running_var \t torch.Size([135])\n",
      "ft_module.0.bn.num_batches_tracked \t torch.Size([])\n",
      "ft_module.1.conv.weight \t torch.Size([29, 212, 1, 1])\n",
      "ft_module.1.bn.weight \t torch.Size([29])\n",
      "ft_module.1.bn.bias \t torch.Size([29])\n",
      "ft_module.1.bn.running_mean \t torch.Size([29])\n",
      "ft_module.1.bn.running_var \t torch.Size([29])\n",
      "ft_module.1.bn.num_batches_tracked \t torch.Size([])\n",
      "ft_module.2.conv.weight \t torch.Size([15, 61, 1, 1])\n",
      "ft_module.2.bn.weight \t torch.Size([15])\n",
      "ft_module.2.bn.bias \t torch.Size([15])\n",
      "ft_module.2.bn.running_mean \t torch.Size([15])\n",
      "ft_module.2.bn.running_var \t torch.Size([15])\n",
      "ft_module.2.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.0.conv.weight \t torch.Size([512, 179, 3, 3])\n",
      "pyramid_ext.0.bn.weight \t torch.Size([512])\n",
      "pyramid_ext.0.bn.bias \t torch.Size([512])\n",
      "pyramid_ext.0.bn.running_mean \t torch.Size([512])\n",
      "pyramid_ext.0.bn.running_var \t torch.Size([512])\n",
      "pyramid_ext.0.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.1.conv.weight \t torch.Size([512, 512, 3, 3])\n",
      "pyramid_ext.1.bn.weight \t torch.Size([512])\n",
      "pyramid_ext.1.bn.bias \t torch.Size([512])\n",
      "pyramid_ext.1.bn.running_mean \t torch.Size([512])\n",
      "pyramid_ext.1.bn.running_var \t torch.Size([512])\n",
      "pyramid_ext.1.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.2.conv.weight \t torch.Size([256, 512, 3, 3])\n",
      "pyramid_ext.2.bn.weight \t torch.Size([256])\n",
      "pyramid_ext.2.bn.bias \t torch.Size([256])\n",
      "pyramid_ext.2.bn.running_mean \t torch.Size([256])\n",
      "pyramid_ext.2.bn.running_var \t torch.Size([256])\n",
      "pyramid_ext.2.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.3.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "pyramid_ext.3.bn.weight \t torch.Size([256])\n",
      "pyramid_ext.3.bn.bias \t torch.Size([256])\n",
      "pyramid_ext.3.bn.running_mean \t torch.Size([256])\n",
      "pyramid_ext.3.bn.running_var \t torch.Size([256])\n",
      "pyramid_ext.3.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.4.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "pyramid_ext.4.bn.weight \t torch.Size([256])\n",
      "pyramid_ext.4.bn.bias \t torch.Size([256])\n",
      "pyramid_ext.4.bn.running_mean \t torch.Size([256])\n",
      "pyramid_ext.4.bn.running_var \t torch.Size([256])\n",
      "pyramid_ext.4.bn.num_batches_tracked \t torch.Size([])\n",
      "pyramid_ext.5.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "pyramid_ext.5.bn.weight \t torch.Size([256])\n",
      "pyramid_ext.5.bn.bias \t torch.Size([256])\n",
      "pyramid_ext.5.bn.running_mean \t torch.Size([256])\n",
      "pyramid_ext.5.bn.running_var \t torch.Size([256])\n",
      "pyramid_ext.5.bn.num_batches_tracked \t torch.Size([])\n",
      "loc.0.weight \t torch.Size([24, 512, 3, 3])\n",
      "loc.0.bias \t torch.Size([24])\n",
      "loc.1.weight \t torch.Size([24, 512, 3, 3])\n",
      "loc.1.bias \t torch.Size([24])\n",
      "loc.2.weight \t torch.Size([24, 256, 3, 3])\n",
      "loc.2.bias \t torch.Size([24])\n",
      "loc.3.weight \t torch.Size([24, 256, 3, 3])\n",
      "loc.3.bias \t torch.Size([24])\n",
      "loc.4.weight \t torch.Size([16, 256, 3, 3])\n",
      "loc.4.bias \t torch.Size([16])\n",
      "loc.5.weight \t torch.Size([16, 256, 3, 3])\n",
      "loc.5.bias \t torch.Size([16])\n",
      "conf.0.weight \t torch.Size([126, 512, 3, 3])\n",
      "conf.0.bias \t torch.Size([126])\n",
      "conf.1.weight \t torch.Size([126, 512, 3, 3])\n",
      "conf.1.bias \t torch.Size([126])\n",
      "conf.2.weight \t torch.Size([126, 256, 3, 3])\n",
      "conf.2.bias \t torch.Size([126])\n",
      "conf.3.weight \t torch.Size([126, 256, 3, 3])\n",
      "conf.3.bias \t torch.Size([126])\n",
      "conf.4.weight \t torch.Size([84, 256, 3, 3])\n",
      "conf.4.bias \t torch.Size([84])\n",
      "conf.5.weight \t torch.Size([84, 256, 3, 3])\n",
      "conf.5.bias \t torch.Size([84])\n"
     ]
    }
   ],
   "source": [
    "w0 = torch.load(\"prune.pth\")\n",
    "for k,v in w0.items():\n",
    "    print (k,'\\t',v.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-54c9ffe49cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m256\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
